# Реализована модель Seq2Seq в архитектуре Encoder-Decoder на pytorch

## Info
1. Набор данных: [набор данных Яндекс Переводчика](https://drive.google.com/file/d/1cfUt8-cJR7gWLv68ya_gZwbIZgq29F7D/view?usp=sharing)
2. Языки перервода: русский и английский
3. В архитектуре модели использованы Embedings и GRU
4. Проведено тестирование
5. **Шаг по улучшению** - увеличение количества эпох
