{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsC7bg63d+J1YL+Ngtjx1X"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import gdown\n",
        "import zipfile\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHbhg_k9ha6E",
        "outputId": "b8f69f95-428d-41e0-c95b-7bcdb590dcb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-3d55082c814b>:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JkDXwWkZmptx",
        "outputId": "ba9f717e-6308-41b8-87dc-d9af46f75f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "1wM1chZ41eUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1cfUt8-cJR7gWLv68ya_gZwbIZgq29F7D'\n",
        "zip_file_path = 'data/1mcorpus.zip'\n",
        "\n",
        "gdown.download(url, zip_file_path, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('data')\n",
        "os.remove(zip_file_path)\n",
        "os.listdir('data/1mcorpus')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdvziMlDft_i",
        "outputId": "091a41e7-204e-4752-c596-c0ff9635a794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1cfUt8-cJR7gWLv68ya_gZwbIZgq29F7D\n",
            "From (redirected): https://drive.google.com/uc?id=1cfUt8-cJR7gWLv68ya_gZwbIZgq29F7D&confirm=t&uuid=49c9f0cf-d701-4f35-bc15-efb8ffbdc973\n",
            "To: /content/data/1mcorpus.zip\n",
            "100%|██████████| 122M/122M [00:02<00:00, 58.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corpus.en_ru.1m.ru', 'corpus.en_ru.1m.en']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('data/1mcorpus/corpus.en_ru.1m.en', 'r', encoding='utf-8') as f:\n",
        "    english_sentences = f.readlines()\n",
        "\n",
        "with open('data/1mcorpus/corpus.en_ru.1m.ru', 'r', encoding='utf-8') as f:\n",
        "    russian_sentences = f.readlines()\n",
        "\n",
        "############\n",
        "english_sentences = english_sentences[:20000]\n",
        "russian_sentences = russian_sentences[:20000]\n",
        "#########\n",
        "\n",
        "print(f\"Количество предложений на английском: {len(english_sentences)}\")\n",
        "print(f\"Количество предложений на русском: {len(russian_sentences)}\")\n",
        "\n",
        "train_size = int(0.8 * len(english_sentences))\n",
        "train_english_sentences = english_sentences[:train_size]\n",
        "train_russian_sentences = russian_sentences[:train_size]\n",
        "\n",
        "test_english_sentences = english_sentences[train_size:]\n",
        "test_russian_sentences = russian_sentences[train_size:]\n",
        "\n",
        "print(f\"Количество обучающих предложений: {len(train_english_sentences)}\")\n",
        "print(f\"Количество тестовых предложений: {len(test_english_sentences)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hNaGo7SgLLf",
        "outputId": "a5fdc739-7870-4040-83df-863fc8d1953f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество предложений на английском: 20000\n",
            "Количество предложений на русском: 20000\n",
            "Количество обучающих предложений: 16000\n",
            "Количество тестовых предложений: 4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "russian_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN9DcPQigL9M",
        "outputId": "222e48c7-1d0f-494c-86ac-e13904411d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Такое развитие характера Гарри может разочаровать читателей, полюбивших его былую мстительность, но с другой стороны это преображение укрепляет позицию тех, кто не видит глубже сюжета и изображения героев.\\n',\n",
              " 'Решение суда (группа вернулась под крыло к Elektra Entertainment) предотвратило дальнейшие нападки со стороны неугомонного Ульриха и не позволило ему обнародовать детали нового контракта.\\n',\n",
              " 'Когда тебе 18 или 19 лет, легко перенимать бандитские повадки и переносить их в группу.\\n',\n",
              " 'А сейчас куча триьютов тем же самым BLACK SABBATH и KISS.\\n',\n",
              " 'Я был единственным, кто занялся копированием демо на кассете.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11DjBPqxgL_z",
        "outputId": "a72b3f26-88d4-4256-a51a-1859babac7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"This new development in Harry's character may be a disappointment to those readers who enjoyed his old vindictive ways, but it also reinforces the position of pro-Potter people who do not see beneath the surface appearance of the characters and plots.\\n\",\n",
              " 'A nondisclosure clause in the final settlement (the band is back on Elektra) prevents Ulrich, an irrepressible motormouth, from providing any juicy contractual details.\\n',\n",
              " \"When you're 18 or 19 years old, you have that gang mentality in your band.\\n\",\n",
              " 'Now you have Black Sabbath and Kiss tribute albums.\\n',\n",
              " 'I was the one who sat down and copied them.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Токенизация текстов\n",
        "russian_tokenizer = get_tokenizer('basic_english')\n",
        "english_tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Построение словарей\n",
        "def build_vocab(sentences, tokenizer):\n",
        "    def yield_tokens(sentences):\n",
        "        for sentence in sentences:\n",
        "            yield tokenizer(sentence)\n",
        "\n",
        "    return build_vocab_from_iterator(yield_tokens(sentences), specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "# Построим словари для русского и английского языков\n",
        "russian_vocab = build_vocab(train_russian_sentences, russian_tokenizer)\n",
        "english_vocab = build_vocab(train_english_sentences, english_tokenizer)\n",
        "\n",
        "# Установим индексы для специальных токенов\n",
        "russian_vocab.set_default_index(russian_vocab['<unk>'])\n",
        "english_vocab.set_default_index(english_vocab['<unk>'])\n",
        "\n",
        "# Проверим размер словарей\n",
        "print(f\"Размер словаря русского языка: {len(russian_vocab)}\")\n",
        "print(f\"Размер словаря английского языка: {len(english_vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hp-3EMrgMCp",
        "outputId": "33007ae5-9e22-4fab-db03-0b05810b3854",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря русского языка: 58411\n",
            "Размер словаря английского языка: 28647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab, src_tokenizer, tgt_tokenizer):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.tgt_sentences = tgt_sentences\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "        self.src_tokenizer = src_tokenizer\n",
        "        self.tgt_tokenizer = tgt_tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_sentence = self.src_sentences[idx]\n",
        "        tgt_sentence = self.tgt_sentences[idx]\n",
        "\n",
        "        src_tokens = [self.src_vocab[token] for token in self.src_tokenizer(src_sentence)]\n",
        "        tgt_tokens = [self.tgt_vocab[token] for token in self.tgt_tokenizer(tgt_sentence)]\n",
        "\n",
        "        return torch.tensor(src_tokens), torch.tensor(tgt_tokens)\n",
        "\n",
        "train_dataset = TranslationDataset(train_russian_sentences, train_english_sentences, russian_vocab, english_vocab, russian_tokenizer, english_tokenizer)\n",
        "test_dataset = TranslationDataset(test_russian_sentences, test_english_sentences, russian_vocab, english_vocab, russian_tokenizer, english_tokenizer)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)"
      ],
      "metadata": {
        "id": "qi2mlAWclkIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        return hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.fc_out.out_features\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        hidden = self.encoder(src)\n",
        "\n",
        "        input = trg[0, :]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "ABuxW3xFlyVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(russian_vocab)\n",
        "OUTPUT_DIM = len(english_vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=english_vocab['<pad>'])\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src, trg = zip(*batch)\n",
        "        src = nn.utils.rnn.pad_sequence(src, padding_value=russian_vocab['<pad>']).to(device)\n",
        "        trg = nn.utils.rnn.pad_sequence(trg, padding_value=english_vocab['<pad>']).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src, trg = zip(*batch)\n",
        "        src = nn.utils.rnn.pad_sequence(src, padding_value=russian_vocab['<pad>']).to(device)\n",
        "        trg = nn.utils.rnn.pad_sequence(trg, padding_value=english_vocab['<pad>']).to(device)\n",
        "\n",
        "        output = model(src, trg, 0)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "N_EPOCHS = 2\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    print('Loss ', train_loss)"
      ],
      "metadata": {
        "id": "WP6-eTowlyYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d502e5ed-b235-4dec-eb70-3e3303ad844c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss  7.292766580581665\n",
            "Loss  6.851080514907837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluate(model, test_loader, criterion)\n",
        "print(test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqeCpFAeoBVs",
        "outputId": "3a45e712-1826-45ba-adb9-85e26703e720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.170359771728515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrXy_4Z4v2Ie",
        "outputId": "c2141f35-66cf-4d8b-d386-b341e76196d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(58411, 256)\n",
              "    (rnn): GRU(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(28647, 256)\n",
              "    (rnn): GRU(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=28647, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence, src_vocab, trg_vocab, src_tokenizer, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    tokens = [token for token in src_tokenizer(sentence)]\n",
        "    tokens = ['<bos>'] + tokens + ['<eos>']\n",
        "    src_indexes = [src_vocab[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    hidden = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_vocab['<bos>']]\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        output, hidden = model.decoder(trg_tensor, hidden)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [trg_vocab.lookup_token(idx) for idx in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1]  # Обрезаем <bos> и <eos>\n",
        "\n",
        "# Функция для перевода и вывода результатов\n",
        "def translate_and_print(model, dataset, src_vocab, trg_vocab, src_tokenizer, device, n_sentences=10):\n",
        "    model.eval()\n",
        "    for i in range(n_sentences):\n",
        "        src_sentence, trg_sentence = dataset[i]\n",
        "        src_sentence_text = ' '.join([src_vocab.lookup_token(idx.item()) for idx in src_sentence])\n",
        "        trg_sentence_text = ' '.join([trg_vocab.lookup_token(idx.item()) for idx in trg_sentence])\n",
        "\n",
        "        translation = translate_sentence(model, src_sentence_text, src_vocab, trg_vocab, src_tokenizer, device)\n",
        "        translation_sentence = ' '.join(translation)\n",
        "\n",
        "        print(f'Исходное предложение: {src_sentence_text}')\n",
        "        print(f'Перевод: {translation_sentence}')\n",
        "        print(f'Ожидаемый перевод: {trg_sentence_text}')\n",
        "        print()\n",
        "\n",
        "translate_and_print(model, test_dataset, russian_vocab, english_vocab, russian_tokenizer, device, n_sentences=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEcqA0ZCoYCC",
        "outputId": "09fe5baa-ecca-487c-8632-5893c9e8dbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходное предложение: он окончательно убедился в том , что отец решил не противодействовать естественному ходу событий иисус был <unk> решимости не прибегать к каким-либо из своих возможностей <unk> , верховного главы своей вселенной , ради собственного спасения .\n",
            "Перевод: the , , the the of of the , , the , of the , of the , , the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of\n",
            "Ожидаемый перевод: he was at last convinced that the father intended to allow natural events to take their course he was fully determined to employ none of his sovereign power as the supreme head of a universe to save himself .\n",
            "\n",
            "Исходное предложение: эти два человека имеют много общего , в том числе <unk> и желание <unk> американскую мощь .\n",
            "Перевод: the the of the the of the the of the the of the the of the and the of the the of the and the of the the of the and the of the the of the and the of the the of the and the of the the\n",
            "Ожидаемый перевод: these two men share much , including <unk> and a desire to revive american power abroad .\n",
            "\n",
            "Исходное предложение: и рейган и обама хотели изменить <unk> соединенных штатов , а с ней и восприятие соединенных штатов в мире .\n",
            "Перевод: the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the\n",
            "Ожидаемый перевод: both reagan and obama set about changing the <unk> of the united states , and with it the perception of the united states in the world .\n",
            "\n",
            "Исходное предложение: эта <unk> сочетается с достаточно успешными <unk> создать совершенно другое отношение к соединенным штатам за рубежом .\n",
            "Перевод: the the of of the the the of the the of the the of the the of the the of the the of the the of the . of the . . the . . the . . . . . . . . . . . . .\n",
            "Ожидаемый перевод: this continuity is combined with a <unk> successful attempt to create an altogether different sensibility about the united states overseas .\n",
            "\n",
            "Исходное предложение: именно в европе стратегия обамы будет <unk> на <unk> .\n",
            "Перевод: the the of the the of the the the of the the of the the of the the of the the of the the of the the of the the of the the of the . of the . . the . of the . . the . .\n",
            "Ожидаемый перевод: and so it is in europe that obama ' s strategy will face its defining moment .\n",
            "\n",
            "Исходное предложение: когда такое устройство <unk> , игрок может использовать звук своего собственного голоса , чтобы отвлечь в игре врагов .\n",
            "Перевод: the , , the the of of the , , the the of of the , , the the of of the , , the the of of the , , the the of of the , of the , of the , of the , of the ,\n",
            "Ожидаемый перевод: when such a device is connected , the player can use the sound of his or her own voice to <unk> <unk> enemies .\n",
            "\n",
            "Исходное предложение: поэтому , большинство времени тратится на негативные риски проекта ( угрозы ) , а не на позитивные ( возможности ) .\n",
            "Перевод: the , , the , of the , , , the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of the , of\n",
            "Ожидаемый перевод: that said , most of the time and focus is spent handling negative project risks , or threats , rather than positive project risks , or opportunities .\n",
            "\n",
            "Исходное предложение: процесс <unk> , если на него требуется столько времени , что он , по всей видимости , никогда не будет выполнен .\n",
            "Перевод: the , , the , of the , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , . .\n",
            "Ожидаемый перевод: the risk management process is not effective if it is so time-consuming that it is never done .\n",
            "\n",
            "Исходное предложение: если в самом начале проекта следовать простому , <unk> и <unk> <unk> управления , который включает в себя семь шагов ( или меньше шагов , если список рисков уже был создан ранее ) , то проектная команда может подготовиться ко всему , что может их ожидать на пути к <unk> .\n",
            "Перевод: the , , the , of the , , the , of the , , the , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n",
            "Ожидаемый перевод: by following a simple , tested , and proven approach that involves seven steps taken at the beginning of each project ( fewer if a generic list of project risks has already been established ) , the project team can prepare itself for whatever may occur .\n",
            "\n",
            "Исходное предложение: мы рекомендуем использовать утилиту для удаления <unk> для безопасного решения проблемы .\n",
            "Перевод: the the of the the of the the of the the of the the of the the of the the of the the of the the of the . of the . . the . of the . . . the . . . the . . . .\n",
            "Ожидаемый перевод: we recommend you to use eclipse 2000 removal tool for safe problem solution .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ez22T_6mvxwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ucHhM3LjvxyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "psiXmF3vvx06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YpX5G12Ivx30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QuSTUWzvvx6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "# Параметры модели\n",
        "INPUT_DIM = len(russian_vocab)\n",
        "OUTPUT_DIM = len(english_vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=english_vocab['<pad>'])\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src, trg = zip(*batch)\n",
        "        src = nn.utils.rnn.pad_sequence(src, padding_value=russian_vocab['<pad>']).to(device)\n",
        "        trg = nn.utils.rnn.pad_sequence(trg, padding_value=english_vocab['<pad>']).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src, trg = zip(*batch)\n",
        "            src = nn.utils.rnn.pad_sequence(src, padding_value=russian_vocab['<pad>']).to(device)\n",
        "            trg = nn.utils.rnn.pad_sequence(trg, padding_value=english_vocab['<pad>']).to(device)\n",
        "\n",
        "            output = model(src, trg, 0)\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "N_EPOCHS = 2\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    print('Loss ', train_loss)\n",
        "\n",
        "# Функция для перевода предложения\n",
        "def translate_sentence(model, sentence, src_vocab, trg_vocab, src_tokenizer, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    tokens = [token for token in src_tokenizer(sentence)]\n",
        "    tokens = ['<bos>'] + tokens + ['<eos>']\n",
        "    src_indexes = [src_vocab[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_vocab['<bos>']]\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(trg_tensor, hidden)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [trg_vocab.lookup_token(idx) for idx in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:-1]  # Обрезаем <bos> и <eos>\n",
        "\n",
        "# Функция для перевода и вывода результатов\n",
        "def translate_and_print(model, dataset, src_vocab, trg_vocab, src_tokenizer, device, n_sentences=10):\n",
        "    model.eval()\n",
        "    for i in range(n_sentences):\n",
        "        src_sentence, trg_sentence = dataset[i]\n",
        "        src_sentence_text = ' '.join([src_vocab.lookup_token(idx.item()) for idx in src_sentence])\n",
        "        trg_sentence_text = ' '.join([trg_vocab.lookup_token(idx.item()) for idx in trg_sentence])\n",
        "\n",
        "        translation = translate_sentence(model, src_sentence_text, src_vocab, trg_vocab, src_tokenizer, device)\n",
        "        translation_sentence = ' '.join(translation)\n",
        "\n",
        "        print(f'Исходное предложение: {src_sentence_text}')\n",
        "        print(f'Перевод: {translation_sentence}')\n",
        "        print(f'Ожидаемый перевод: {trg_sentence_text}')\n",
        "        print()\n",
        "\n",
        "# Пример использования\n",
        "translate_and_print(model, test_dataset, russian_vocab, english_vocab, russian_tokenizer, device, n_sentences=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j21nPJ4Bpkwr",
        "outputId": "6ba6d278-0a92-44be-fc8e-09f41b2ac228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss  7.280425794601441\n",
            "Loss  6.774588759422302\n",
            "Исходное предложение: он окончательно убедился в том , что отец решил не противодействовать естественному ходу событий иисус был <unk> решимости не прибегать к каким-либо из своих возможностей <unk> , верховного главы своей вселенной , ради собственного спасения .\n",
            "Перевод: , the the the the the that the is not to the the the of the the , of the , , the the the the of the the , of the the , of the the , of the the . of the . . the . .\n",
            "Ожидаемый перевод: he was at last convinced that the father intended to allow natural events to take their course he was fully determined to employ none of his sovereign power as the supreme head of a universe to save himself .\n",
            "\n",
            "Исходное предложение: эти два человека имеют много общего , в том числе <unk> и желание <unk> американскую мощь .\n",
            "Перевод: , the the the the and of the and and and the the and of the and and the the . of the . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Ожидаемый перевод: these two men share much , including <unk> and a desire to revive american power abroad .\n",
            "\n",
            "Исходное предложение: и рейган и обама хотели изменить <unk> соединенных штатов , а с ней и восприятие соединенных штатов в мире .\n",
            "Перевод: and and and and and and the and and and the and and the and and the and of the and and the . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Ожидаемый перевод: both reagan and obama set about changing the <unk> of the united states , and with it the perception of the united states in the world .\n",
            "\n",
            "Исходное предложение: эта <unk> сочетается с достаточно успешными <unk> создать совершенно другое отношение к соединенным штатам за рубежом .\n",
            "Перевод: of the the the the of the the of the the of the the . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Ожидаемый перевод: this continuity is combined with a <unk> successful attempt to create an altogether different sensibility about the united states overseas .\n",
            "\n",
            "Исходное предложение: именно в европе стратегия обамы будет <unk> на <unk> .\n",
            "Перевод: in the . of the . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Ожидаемый перевод: and so it is in europe that obama ' s strategy will face its defining moment .\n",
            "\n",
            "Исходное предложение: когда такое устройство <unk> , игрок может использовать звук своего собственного голоса , чтобы отвлечь в игре врагов .\n",
            "Перевод: , the the the the the , of the , , the the the , of the , , the the the of the . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Ожидаемый перевод: when such a device is connected , the player can use the sound of his or her own voice to <unk> <unk> enemies .\n",
            "\n",
            "Исходное предложение: поэтому , большинство времени тратится на негативные риски проекта ( угрозы ) , а не на позитивные ( возможности ) .\n",
            "Перевод: , the the the , , the the ( ) ) ) ( ) ) ) ( ) ) ) ) ( ) ) ) ) ( ) ) ) ) ( ) ) ) ) ( ) ) ) ) . ) . ) . ) . the\n",
            "Ожидаемый перевод: that said , most of the time and focus is spent handling negative project risks , or threats , rather than positive project risks , or opportunities .\n",
            "\n",
            "Исходное предложение: процесс <unk> , если на него требуется столько времени , что он , по всей видимости , никогда не будет выполнен .\n",
            "Перевод: , the the the , , the , , not not not to the , , but it is not not to the . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Ожидаемый перевод: the risk management process is not effective if it is so time-consuming that it is never done .\n",
            "\n",
            "Исходное предложение: если в самом начале проекта следовать простому , <unk> и <unk> <unk> управления , который включает в себя семь шагов ( или меньше шагов , если список рисков уже был создан ранее ) , то проектная команда может подготовиться ко всему , что может их ожидать на пути к <unk> .\n",
            "Перевод: , the the the , , the , , , , or , , , , , , or , or , , , , , , , , or , or , , , , , , , , or , or , or , , , ,\n",
            "Ожидаемый перевод: by following a simple , tested , and proven approach that involves seven steps taken at the beginning of each project ( fewer if a generic list of project risks has already been established ) , the project team can prepare itself for whatever may occur .\n",
            "\n",
            "Исходное предложение: мы рекомендуем использовать утилиту для удаления <unk> для безопасного решения проблемы .\n",
            "Перевод: , the the the the the of the the . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Ожидаемый перевод: we recommend you to use eclipse 2000 removal tool for safe problem solution .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFXu-8PVnY-9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}